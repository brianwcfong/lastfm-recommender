---
title: "Last.fm Recommender"
author: "Brian"
date: "September 28, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1) SQL Clickstream Query (MySQL)
Find the count of users who install the app (i.e. with FIRST_INSTALL event) on 2017-04-01 and use our app at least once (i.e. with any event) between 2017-04-02 and 2017-04-08.
Table name: piwik_track
- Table fields:
- uid [string]: Unique ID of user
- time [datetime]: The time when we receive the event
- event_name string ENUM { FIRST_INSTALL, ... } type of event
```{r Clickstream Query SQL}

#SELECT COUNT(DISTINCT uid) AS usercount
#FROM piwik_track
#WHERE 
#  (DATE(time) = '2017-04-01' AND event_name LIKE '%FIRST_INSTALL%') AND
#  (DATE(time) BETWEEN '2017-04-02' AND '2017-04-08')

SELECT COUNT(DISTINCT uid) AS usercount
FROM (
      SELECT uid, time, event_name
        FROM piwik_track
        WHERE
            (DATE(time) BETWEEN '2017-04-02' AND '2017-04-08') AND
            (event_name NOT LIKE '%FIRST_INSTALL%')
    )
WHERE
    (DATE(time) = '2017-04-01' AND event_name LIKE '%FIRST_INSTALL%') 
```

# Libraries for R
```{r}
library(dplyr)
library(lubridate)
library(tidyverse)
library(knitr)
library(wordcloud)
library(recommenderlab)
library(reshape2)
library(shiny)
```


# 2) Raw Data Analytics (R)
Count the total data transfer (namely the sum of the file size of individual request) caused by JPEG files (i.e. URI ends with jpg) from 24th Aug to 25th Aug
```{r Raw Data Analytics}


df <- read.table("./logfile.txt", sep="\t", header=TRUE, stringsAsFactors = FALSE)
df$date <- ymd(df$date)

df %>%  filter(date >= "2017-08-24" & date <= "2017-08-25") %>% filter(grepl(".jpg$",url)) %>% select(size) %>% sum()
# [1] 85251
```

# 3) Last.fm Recommendation Engine (R)
```{r pressure, echo=FALSE}
#train <- read.csv("./offsite-tagging-training-set.csv", #stringsAsFactors = FALSE, header = TRUE, sep=",", encoding = "UTF-8")

# Read profile and plays TSV data

profile <- read.table("./lastfm-dataset-360K/usersha1-profile.tsv", sep="\t", header=FALSE, stringsAsFactors = FALSE)
colnames(profile) <- c("userid","gender","age","country","signup")

playcount <- read.table("./lastfm-dataset-360K/usersha1-artmbid-artname-plays.tsv", sep="\t", fill=TRUE, quote="", stringsAsFactors = FALSE)
colnames(playcount) <- c("userid","artistid","artist","plays")

## Merge profile and playcount
x <- merge(playcount, profile, all.x=TRUE, by.x="userid", by.y="userid")

## Create Male/Female datasets from playcount
female <- x %>% filter(gender=="f")
#male <- x %>% filter(gender=="m")

## Create dimension table for unique artists
uniqueartists <- x %>% select(artistid, artist) %>% unique() %>% as.data.frame() %>% filter(artistid != "")

unique_users <- unique(female$userid)

```

# Wordcloud visualization and simple EDA for male and female

```{r}
female.aggr <- aggregate(plays ~ artistid, female, sum)
female.aggr <- female.aggr[order(-female.aggr$plays),]
female.aggr[,"female_rank"] <- rank(-female.aggr$plays, ties.method="first")


male.aggr <- aggregate(plays ~ artist, male, sum)
male.aggr <- male.aggr[order(-male.aggr$plays),]
male.aggr[,"male_rank"] <- rank(-male.aggr$plays, ties.method="first")


plot.female <- wordcloud(female.aggr$artist, female.aggr$plays, max.words=100)
plot.male <- wordcloud(male.aggr$artist, male.aggr$plays, max.words=100)

z <- merge(male.aggr, female.aggr, all.x=TRUE, all.y=TRUE, by.x="artist", by.y="artist")
z <- z[order(-z$plays.x),]
kable(head(z, 50))

# As seen in the Top 50 artists, males and females have different tastes in music
```

# User Based Collaborative Filter to create Recommender for female users (using only female users)
```{r}
# Looking at number of female users and how many artists they listen to
length(unique(female$userid))
# [1] 1328 unique female users
length(unique(female$artistid))
# [1] 15091 unique artists

# No. of rows with empty artistid, and remove them
nrow(female[female$artistid == "",])
# [1] 837
female <- female %>% filter(artistid != "")

# No. of rows with empty artist, and remove them
nrow(female[female$artist == "",])
# [1] 5
female <- female %>% filter(artist != "")

# Transform data to user/artist matrix
female.matrix <- acast(female, userid ~ artistid, fun.aggregate=sum, value.var="plays")
# Double check if matrix has correct dimensions
nrow(female.matrix)
# [1] 1328 = total unique users
ncol(female.matrix)
# [1] 15089 = total unique artists

sum(female$plays, na.rm=TRUE)
# [1] 12783183 = total plays in dataframe
sum(female.matrix, na.rm=TRUE)
# [1] 12783183 = total plays in matrix

# Convert all 0 to NA for recommenderlab to work
female.matrix[female.matrix == 0] <- NA

# Transform into realRatingMatrix for recommenderlab
female.real <- as(female.matrix,"realRatingMatrix")

# Used first 1000 female users as training data
# Method for normalization was centering instead of Z-score, may yield improvements with Z-score or other normalization
# nn = 50 nearest neighbours can be hypertuned using cross-validation for better model in the future
rec.model <-Recommender(female.real[1:1000], method = "UBCF", param=list(normalize = "center",method="Cosine",nn=50))
 
# Used remaining 1001-1328 users as test data
as.data.frame(as(predict(rec.model, female.real[1001:1328], n=10), "list"))
```

# Seeing if PCA can be used to reduce dimensionality
Attempted to use Principal Component Analysis to reduce number of different artists into groups, but was not very effective overall.

Based on the plot, 10 PCs only explained about 60% of the total variance in the dataset, indicating that artists were not 

As there were no genre or other artist tags within the Last.fm data, we are unable to deduce whether these PCs are a representation of the Genres or other categories of artists, or there are other segments of artists that can be used for better recommendations in the future.

A better use would be to utilize artist's "Genre", "Decade" (e.g. 60s, 70s) or other tags available from MusicBrains/Last.fm as features to improve the recommendation engine instead of PCA.
```{r}
# Change NAs to 0 in matrix
female.matrix[is.na(female.matrix)] <- 0

# Find and remove zero variance columns, as PCA does not work if columns are entirely zero variance
which(apply(female.matrix, 2, var)==0)
female.matrix <- female.matrix[ , apply(female.matrix, 2, var) != 0]

# Calculate PCA with normalization and centered to 0
female.pca <- prcomp(female.matrix, center = TRUE, scale = TRUE)
plot(female.pca, type="l")

# Biplot to view direction of principal components
# Biplot was attempted but it does not yield much information about the PCs that is useful at this point
#biplot(female.pca, scale = 0)

```

# Item based Collaborative Filtering
An attempt was made to use Item Based Collaborative Filtering for a recommendation engine. However, performance was much worse without significant improvement to the recommendations, due to the size of the matrix required for cosine similarity between 15,000+ artists.

The top 100 artists for females was used in this version below (100x100 matrix for cosine similarity) as a proof of concept. However, User-based seems to be more effective.
```{r}
#library(lsa)
# Library for cosine similarity calculation, was not used for the final IBCF

# Try top 100 female artists only for performance
top100 <- female.aggr %>% filter(female_rank <= 100) %>% select(artistid)
top100 <- as.vector(top100[,1])

# Keep only rows with artistid in top100
femaletop100 <- female %>% filter(artistid %in% top100)
femaletop100 <- femaletop100 %>% filter(artistid != "")

#
femaletop100.matrix <- acast(femaletop100, userid ~ artistid, fun.aggregate=sum, value.var="plays")

# Convert NAs to zero
femaletop100.matrix[femaletop100.matrix == 0] <- NA

# Artist Cosine Similarity (Item-based); cosine function from lsa package
#artist_sim <- cosine(femaletop100.matrix)

femaletop100.real <- as(femaletop100.matrix,"realRatingMatrix")

rec.model <-Recommender(femaletop100.real[1:1000], method = "IBCF")

predict_user <- predict(rec.model, femaletop100.real[1001:nrow(femaletop100.matrix)], n=5)

as(predict_user,"list")
```

